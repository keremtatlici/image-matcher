{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import kerem\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "root_path = '../datasets/'\n",
    "file_names = [f for f in listdir(root_path) if isfile(join(root_path, f))]\n",
    "\n",
    "image_storage = dict()\n",
    "\n",
    "for file_name in file_names:\n",
    "    image_storage[file_name.split('.')[0]] = cv2.imread(root_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = image_storage['mf01']\n",
    "img2 = image_storage['wf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#kerem.show_images([kerem.resize_image(img1,3), kerem.resize_image(img2,3)])\n",
    "kerem.show_images([img1, img2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create(hessianThreshold=400, )\n",
    "kp1, des1 = surf.detectAndCompute(img1,None)\n",
    "kp2, des2 = surf.detectAndCompute(img2,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144557\n",
      "24933\n"
     ]
    }
   ],
   "source": [
    "print(len(kp1))\n",
    "print(len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Step 2: Matching descriptor vectors with a FLANN based matcher\n",
    "# Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "knn_matches = matcher.knnMatch(des1, des2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Filter matches using the Lowe's ratio test\n",
    "ratio_thresh = 0.6\n",
    "good_matches = []\n",
    "for m,n in knn_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)\n",
    "len(good_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 90,  82,  69],\n",
       "        [ 92,  83,  70],\n",
       "        [ 91,  82,  69],\n",
       "        ...,\n",
       "        [133, 121, 115],\n",
       "        [126, 112, 106],\n",
       "        [129, 115, 109]],\n",
       "\n",
       "       [[ 93,  83,  73],\n",
       "        [ 94,  84,  74],\n",
       "        [ 95,  83,  71],\n",
       "        ...,\n",
       "        [137, 125, 121],\n",
       "        [136, 122, 116],\n",
       "        [132, 118, 112]],\n",
       "\n",
       "       [[ 98,  86,  76],\n",
       "        [ 98,  86,  76],\n",
       "        [ 94,  85,  72],\n",
       "        ...,\n",
       "        [135, 122, 120],\n",
       "        [134, 122, 116],\n",
       "        [133, 121, 115]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 69,  69,  63],\n",
       "        [ 72,  69,  64],\n",
       "        [ 72,  70,  62],\n",
       "        ...,\n",
       "        [131, 120, 112],\n",
       "        [131, 121, 111],\n",
       "        [130, 120, 110]],\n",
       "\n",
       "       [[ 68,  65,  61],\n",
       "        [ 72,  69,  65],\n",
       "        [ 73,  71,  63],\n",
       "        ...,\n",
       "        [129, 118, 110],\n",
       "        [132, 120, 110],\n",
       "        [130, 118, 108]],\n",
       "\n",
       "       [[ 74,  70,  65],\n",
       "        [ 75,  71,  66],\n",
       "        [ 75,  73,  65],\n",
       "        ...,\n",
       "        [125, 116, 106],\n",
       "        [128, 119, 106],\n",
       "        [130, 121, 108]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Draw matches\n",
    "img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
    "cv2.drawMatches(img1, kp1, img2, kp2, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Localize the object\n",
    "obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "for i in range(len(good_matches)):\n",
    "    #-- Get the keypoints from the good matches\n",
    "    obj[i,0] = kp1[good_matches[i].queryIdx].pt[0]\n",
    "    obj[i,1] = kp1[good_matches[i].queryIdx].pt[1]\n",
    "    scene[i,0] = kp2[good_matches[i].trainIdx].pt[0]\n",
    "    scene[i,1] = kp2[good_matches[i].trainIdx].pt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, _ =  cv2.findHomography(obj, scene, cv2.RANSAC)\n",
    "#-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "obj_corners[0,0,0] = 0\n",
    "obj_corners[0,0,1] = 0\n",
    "obj_corners[1,0,0] = img1.shape[1]\n",
    "obj_corners[1,0,1] = 0\n",
    "obj_corners[2,0,0] = img1.shape[1]\n",
    "obj_corners[2,0,1] = img1.shape[0]\n",
    "obj_corners[3,0,0] = 0\n",
    "obj_corners[3,0,1] = img1.shape[0]\n",
    "scene_corners = cv2.perspectiveTransform(obj_corners, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 90,  82,  69],\n",
       "        [ 92,  83,  70],\n",
       "        [ 91,  82,  69],\n",
       "        ...,\n",
       "        [133, 121, 115],\n",
       "        [126, 112, 106],\n",
       "        [129, 115, 109]],\n",
       "\n",
       "       [[ 93,  83,  73],\n",
       "        [ 94,  84,  74],\n",
       "        [ 95,  83,  71],\n",
       "        ...,\n",
       "        [137, 125, 121],\n",
       "        [136, 122, 116],\n",
       "        [132, 118, 112]],\n",
       "\n",
       "       [[ 98,  86,  76],\n",
       "        [ 98,  86,  76],\n",
       "        [ 94,  85,  72],\n",
       "        ...,\n",
       "        [135, 122, 120],\n",
       "        [134, 122, 116],\n",
       "        [133, 121, 115]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 69,  69,  63],\n",
       "        [ 72,  69,  64],\n",
       "        [ 72,  70,  62],\n",
       "        ...,\n",
       "        [131, 120, 112],\n",
       "        [131, 121, 111],\n",
       "        [130, 120, 110]],\n",
       "\n",
       "       [[ 68,  65,  61],\n",
       "        [ 72,  69,  65],\n",
       "        [ 73,  71,  63],\n",
       "        ...,\n",
       "        [129, 118, 110],\n",
       "        [132, 120, 110],\n",
       "        [130, 118, 108]],\n",
       "\n",
       "       [[ 74,  70,  65],\n",
       "        [ 75,  71,  66],\n",
       "        [ 75,  73,  65],\n",
       "        ...,\n",
       "        [125, 116, 106],\n",
       "        [128, 119, 106],\n",
       "        [130, 121, 108]]], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "cv2.line(img_matches, (int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "    (int(scene_corners[1,0,0] + img1.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "cv2.line(img_matches, (int(scene_corners[1,0,0] + img1.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "    (int(scene_corners[2,0,0] + img1.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "cv2.line(img_matches, (int(scene_corners[2,0,0] + img1.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "    (int(scene_corners[3,0,0] + img1.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "cv2.line(img_matches, (int(scene_corners[3,0,0] + img1.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "    (int(scene_corners[0,0,0] + img1.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerem.show_images(\n",
    "    [img_matches],\n",
    "    divided_by=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
